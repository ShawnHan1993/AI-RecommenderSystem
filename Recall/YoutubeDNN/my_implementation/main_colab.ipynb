{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15462,"status":"ok","timestamp":1697253907690,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"CLskas6raMq0","outputId":"684ac325-9e60-4cc7-a19a-4d811789fc29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: tf_sentence_transformers in /usr/local/lib/python3.10/dist-packages (0.2)\n","Requirement already satisfied: tensorflow>=2 in /usr/local/lib/python3.10/dist-packages (from tf_sentence_transformers) (2.13.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from tf_sentence_transformers) (4.34.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (1.59.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (3.9.0)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2->tf_sentence_transformers) (0.34.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (0.17.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (0.14.1)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->tf_sentence_transformers) (4.66.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2->tf_sentence_transformers) (0.41.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers->tf_sentence_transformers) (2023.6.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (3.5)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (3.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->tf_sentence_transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->tf_sentence_transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->tf_sentence_transformers) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->tf_sentence_transformers) (2023.7.22)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (1.3.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2->tf_sentence_transformers) (3.2.2)\n"]}],"source":["import os\n","IS_COLAB_ENV = True\n","\n","try:\n","    from google.colab import drive\n","    IS_COLAB_ENV = True\n","except:\n","    IS_COLAB_ENV = False\n","\n","if IS_COLAB_ENV:\n","    drive.mount('/content/drive')\n","    !pip install einops\n","    !pip install tf_sentence_transformers\n","    ROOT_DIR = \"/content/drive/MyDrive/work/AI-RecommenderSystem/\"\n","    os.chdir('/content/drive/MyDrive/work/' + 'AI-RecommenderSystem/Recall/YoutubeDNN/my_implementation')\n","else:\n","    ROOT_DIR = \"/mnt/g/My Drive/work/AI-RecommenderSystem/\"\n","\n","try:\n","    os.chdir(ROOT_DIR + 'Recall/YoutubeDNN/my_implementation')\n","except FileNotFoundError:\n","    ROOT_DIR = \"/Users/hanshen/Library/CloudStorage/GoogleDrive-shawnhan1029@gmail.com/My Drive/work/AI-RecommenderSystem/\"\n","    os.chdir(ROOT_DIR + 'Recall/YoutubeDNN/my_implementation')\n","DATA_DIR = ROOT_DIR + \"Dataset/news_data_bigger/\"\n"]},{"cell_type":"markdown","metadata":{"id":"afKSoRULaIGi"},"source":["# LOAD USER AND DOC INFO"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6630,"status":"ok","timestamp":1697253914317,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"TIdEW3LJaIGk"},"outputs":[],"source":["from collections import namedtuple\n","import pandas as pd\n","from typing import Dict\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import os, pickle\n","from tf_sentence_transformers import SentenceTransformer\n","\n","\n","user_info_cols = [\"userid\", \"device\", \"operating_system\", \"province\", \"city\", \"age\", \"gender\"]\n","doc_info_cols = [\"docid\", \"title\", \"create_time\", \"image_num\", \"cate1\", \"cate2\", \"keywords\"]\n","show_info_cols = [\"userid\", \"docid\", \"exp_time\", \"network\", \"rt\", \"rit\", \"click\", \"reading_time\"]"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1125,"status":"ok","timestamp":1697253917748,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"k5qFFVXdFEVM","outputId":"1b8bc751-3a00-4daf-b239-be95879a5d27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found GPU at: /device:GPU:0\n"]}],"source":["import re\n","device_name = tf.test.gpu_device_name()\n","if len(device_name) > 0:\n","    USE_GPU = True\n","    print(\"Found GPU at: {}\".format(device_name))\n","else:\n","    USE_GPU = False\n","    device_name = tf.config.list_physical_devices('CPU')[0].name\n","    device_name = re.sub(\"physical_device:\", \"\", device_name)\n","    print(\"No GPU, using {}.\".format(device_name))"]},{"cell_type":"markdown","metadata":{"id":"NwvMDtKd6-8S"},"source":["# BUILD converter_layers"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697253917748,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"v6yBBHMraIGp"},"outputs":[],"source":["feat_names = [\n","    \"userid\",\n","    \"device\",\n","    \"operating_system\",\n","    \"province\",\n","    \"city\",\n","    \"age\",\n","    \"gender\",\n","    # \"docid\",\n","    \"network\",\n","    \"rt\",\n","    \"rit\",\n","    \"cate1\",\n","    \"cate2\",\n","    \"title\",\n","]\n","\n","\n","CATE_FEAT = set([\n","    \"userid\",\n","    \"device\",\n","    \"operating_system\",\n","    \"province\",\n","    \"city\",\n","    \"age\",\n","    \"gender\",\n","    \"docid\",\n","    \"network\",\n","    \"rt\",\n","    \"rit\",\n","    \"cate1\",\n","    \"cate2\",\n","])\n","\n","TEXT_FEAT = set([\n","    \"title\"\n","])\n","\n","\n","def clean_create_time(value):\n","    if len(value) == 0:\n","        return np.uint32(0)\n","    return np.uint32(value)\n","\n","def clean_image_num(value):\n","    if len(value) == 0:\n","        return np.uint8(0)\n","    return np.uint8(value)\n","\n","def reduce_proba(row: str):\n","    '''Suppose row has the following format: key1:[float],key2:[float]\n","    '''\n","    if not isinstance(row, str):\n","        return \"UNK\"\n","    if len(row) == 0:\n","        return \"UNK\"\n","    classes = row.split(\",\")\n","    assert len(classes) >= 1, \"unkown format: [{}]\".format(row)\n","    max_proba = 0\n","    max_class = \"UNK\"\n","    for cls_pair in classes:\n","        cls, proba = cls_pair.split(\":\")\n","        if float(proba) > max_proba:\n","            max_class = cls\n","            max_proba = float(proba)\n","    return max_class\n","\n","\n","def get_vocab(feat: str):\n","    assert feat in CATE_FEAT, \"not support feat!\"\n","    global user_info, doc_info, show_info\n","    if feat in user_info_cols:\n","        if user_info is None:\n","            user_info = pd.read_csv(\n","                DATA_DIR + \"user_info.txt\",\n","                sep=\"\\t\", header=None, names=user_info_cols,\n","                dtype=str,\n","                keep_default_na=False\n","            )\n","            user_info[\"age\"] = user_info[\"age\"].apply(reduce_proba)\n","            user_info[\"gender\"] = user_info[\"gender\"].apply(reduce_proba)\n","        return user_info[feat].unique()\n","    if feat in doc_info:\n","        if doc_info is None:\n","            doc_info = pd.read_csv(\n","                DATA_DIR + \"doc_info.txt\",\n","                sep=\"\\t\", header=None, names=doc_info_cols,\n","                # converters={\n","                #     \"create_time\": clean_create_time,\n","                #     \"image_num\": clean_image_num,\n","                # },\n","                dtype=str,\n","                keep_default_na=False\n","            )\n","        return doc_info[feat].unique()\n","    if feat in show_info_cols:\n","        if show_info_cols is None:\n","            show_info = pd.read_csv(\n","                DATA_DIR + \"sorted_train_data.txt\",\n","                sep=\"\\t\", names=show_info_cols,\n","                dtype=str,\n","                keep_default_na=False,\n","                nrows=1000000,\n","            )\n","        return show_info[feat].unique()\n","    raise Exception(\"Dont know where to find {}\".format(feat))\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":19609,"status":"ok","timestamp":1697253937354,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"iiL_71vC71BL"},"outputs":[],"source":["user_info: pd.DataFrame = pd.read_csv(\n","    DATA_DIR + \"user_info.txt\",\n","    sep=\"\\t\", header=None, names=user_info_cols,\n","    dtype=str,\n","    keep_default_na=False\n",")\n","user_info[\"age\"] = user_info[\"age\"].apply(reduce_proba)\n","user_info[\"gender\"] = user_info[\"gender\"].apply(reduce_proba)\n","doc_info: pd.DataFrame = pd.read_csv(\n","    DATA_DIR + \"doc_info.txt\",\n","    sep=\"\\t\", header=None, names=doc_info_cols,\n","    # converters={\n","    #     \"create_time\": clean_create_time,\n","    #     \"image_num\": clean_image_num,\n","    # },\n","    dtype=str,\n","    keep_default_na=False,\n","    # nrows=633388,\n",")\n","show_info: pd.DataFrame = None"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11945,"status":"ok","timestamp":1697253949295,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"k9YyATBXaIGq","outputId":"2e076819-2ce5-4a9c-f5e0-e8672861da12"},"outputs":[{"name":"stdout","output_type":"stream","text":["trying to load userid StringLookup layer...\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7bf6cc32c5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["trying to load device StringLookup layer...\n","trying to load operating_system StringLookup layer...\n","trying to load province StringLookup layer...\n","trying to load city StringLookup layer...\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:6 out of the last 6 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7bf6d0591d80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"name":"stdout","output_type":"stream","text":["trying to load age StringLookup layer...\n","trying to load gender StringLookup layer...\n","trying to load network StringLookup layer...\n","trying to load rt StringLookup layer...\n","trying to load rit StringLookup layer...\n","trying to load cate1 StringLookup layer...\n","trying to load cate2 StringLookup layer...\n","trying to download bert model...\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]}],"source":["converter_layers: Dict[str, keras.layers.StringLookup] = {}\n","\n","for key in feat_names:\n","    if key in CATE_FEAT:\n","        if os.path.exists(\"./{}.pkl\".format(key)):\n","            print(\"trying to load {} StringLookup layer...\".format(key))\n","            from_disk = pickle.load(open(\"./{}.pkl\".format(key), \"rb\"))\n","            new_layer = keras.layers.StringLookup().from_config(from_disk[\"config\"])\n","            new_layer.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n","            new_layer.set_weights(from_disk['weights'])\n","        else:\n","            vocab = get_vocab(key)\n","            print(\"trying to create {} StringLookup layer...\".format(key))\n","            new_layer = keras.layers.StringLookup(num_oov_indices=1)\n","            new_layer.adapt(data=vocab)\n","            pickle.dump({\n","                \"config\": new_layer.get_config(),\n","                \"weights\": new_layer.get_weights(),\n","            }, open(\"./{}.pkl\".format(key), \"wb\"))\n","    elif key == \"title\":\n","        print(\"trying to download bert model...\")\n","        with tf.device(device_name):\n","            new_layer = SentenceTransformer.from_pretrained('uer/sbert-base-chinese-nli', from_pt=True)\n","    else:\n","        raise ValueError(\"unsupported feat [\" + key + \"]!\")\n","    converter_layers[key] = new_layer"]},{"cell_type":"markdown","metadata":{"id":"-ZtmrZ1VaIGq"},"source":["## click sequence (one time)"]},{"cell_type":"markdown","metadata":{"id":"BHZK58FLaIGq"},"source":["### make seq file"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697253949295,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"VR3cMtd5aIGq"},"outputs":[],"source":["# from collections import deque\n","\n","# SEQ_LENGTH = 20\n","\n","# ShowLog = namedtuple(\"Userinfo\", [\"userid\", \"docid\", \"exp_time\", \"network\", \"rt\", \"rit\", \"click\", \"reading_time\"])\n","\n","# user_seq_buffer: Dict[str, deque] = {}\n","\n","# with open(DATA_DIR + \"sorted_train_data.txt\", \"r\") as show_log_f, open(DATA_DIR + \"clk_seq_from_sorted_train_data.txt\", 'w') as seq_f:\n","#     for line in show_log_f:\n","#         parts = line[:-1].split(\"\\t\")\n","#         show_log = ShowLog(*parts)\n","#         if show_log.userid not in user_seq_buffer:\n","#             user_seq_buffer[show_log.userid] = deque(maxlen=SEQ_LENGTH)\n","#         dq_of_this_user = user_seq_buffer[show_log.userid]\n","#         seq_str = \" \".join(dq_of_this_user)\n","#         seq_f.write(\",\".join(show_log[:3] + (seq_str,)) + \"\\n\")\n","#         if show_log.click == \"1\":\n","#             dq_of_this_user.append(show_log.docid)"]},{"cell_type":"markdown","metadata":{"id":"M3aP9jAgaIGr"},"source":["### make dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1697253949295,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"2pnDVQ4baIGr"},"outputs":[],"source":["def get_seq_feat(ele):\n","    ele = tf.strings.split(ele, \",\").to_tensor()\n","    # tf.print(\"1\", ele, tf.shape(ele))\n","    ele = ele[:, 3]\n","    # tf.print(\"2\", ele, tf.shape(ele))\n","    ele = tf.strings.split(ele, \" \").to_tensor()\n","    # tf.print(\"3\", ele, tf.shape(ele))\n","    res = converter_layers[\"docid\"](ele)\n","    # tf.print(res, type(res), tf.shape(res))\n","    return res\n","\n","\n","if \"docid\" in feat_names:\n","    seq_dataset = tf.data.TextLineDataset([DATA_DIR + \"/clk_seq_from_sorted_train_data.txt\"])\\\n","        .batch(1024, drop_remainder=True)\\\n","        .map(get_seq_feat)\n","        # .unbatch()\n","else:\n","    seq_dataset = None"]},{"cell_type":"markdown","metadata":{"id":"WTxuujUgA1uj"},"source":["## make title embedding file"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":570,"status":"ok","timestamp":1697254491270,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"lFu8_v_BQDak"},"outputs":[],"source":["doc_info.loc[510178, 'title'] = '\"最强鸿蒙概念股”润和软件再收关注函!20多天5倍涨幅,散户抱团到尽头?'"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167239,"status":"ok","timestamp":1697254670574,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"7W3RtHnKA1uj","outputId":"442b376d-f518-488e-febf-96e1faa67061"},"outputs":[{"name":"stdout","output_type":"stream","text":["wrote number: 510178\n","Still need to process 82568 docs.\n","mode:  a\n"]},{"name":"stderr","output_type":"stream","text":["82568it [02:46, 496.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Done generate.\n"]}],"source":["from tqdm import tqdm\n","\n","# for member in tqdm(members):\n","#     # current contents of your for loop\n","\n","\n","def write_block(input_blk, mode, idx, tmp_ids):\n","    title_as_tensor = tf.constant(input_blk)\n","    with tf.device(device_name):\n","        res_as_tensor = converter_layers[\"title\"](title_as_tensor)\n","    res_as_list = res_as_tensor.numpy().tolist()\n","    lines_blk = []\n","    for id, one_res in zip(tmp_ids, res_as_list):\n","        one_res = [str(round(e, 5)) for e in one_res]\n","        lines_blk.append(id + \",\" + \" \".join(one_res) + \"\\n\")\n","    with open(DATA_DIR + \"doc_title_embedding.txt\", mode) as title_embedding_file, open(DATA_DIR + \"doc_title_embedding_info.txt\", \"w\") as info_file:\n","        title_embedding_file.writelines(lines_blk)\n","        info_file.write(str(idx + 1))\n","\n","\n","DOC_NUMBER = doc_info.shape[0]\n","# DOC_NUMBER = 30\n","\n","\n","if \"title\" in feat_names:\n","    if os.path.exists(DATA_DIR + \"doc_title_embedding_info.txt\"):\n","        with open(DATA_DIR + \"doc_title_embedding_info.txt\" ,\"r\") as info_file:\n","            number_str = info_file.readline()\n","            appended_number = int(number_str)\n","    else:\n","        appended_number = 0\n","    print(\"wrote number: \" + str(appended_number))\n","    if appended_number >= DOC_NUMBER:\n","        print(\"No need to generate.\")\n","        pass\n","    else:\n","        print(\"Still need to process {} docs.\".format(str(DOC_NUMBER - appended_number)))\n","        if appended_number == 0:\n","            mode = \"w\"\n","        else:\n","            mode = \"a\"\n","        print(\"mode: \", mode)\n","        input_blk = []\n","        tmp_ids = []\n","        doc_info__ = doc_info.loc[appended_number:DOC_NUMBER-1, :]\n","        for idx, row in tqdm(doc_info__.iterrows()):\n","            input_blk.append([row[\"title\"]])\n","            tmp_ids.append(row[\"docid\"])\n","            if len(tmp_ids) >= 500:\n","                write_block(input_blk, mode, idx, tmp_ids)\n","                tmp_ids.clear()\n","                input_blk.clear()\n","                mode = \"a\"\n","        if len(tmp_ids) > 0:\n","            write_block(input_blk, mode, idx, tmp_ids)\n","            pass\n","        print(\"Done generate.\")"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":83037,"status":"ok","timestamp":1697254791680,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"oCEWLgk8A1uj"},"outputs":[],"source":["title_embd_table = tf.lookup.experimental.MutableHashTable(\n","    key_dtype=tf.int64,\n","    value_dtype=tf.float32,\n","    default_value=[0.0] * 768,\n",")\n","\n","def build_title_embd_hash_table(ele):\n","    ele = tf.strings.split(ele, \",\").to_tensor()\n","    # tf.print(ele[:, 0], type(ele), ele.shape)\n","    key = tf.strings.to_number([ele[:, 0]], out_type=tf.int64)\n","    value_as_a_whole = tf.strings.split(ele[:, 1], \" \").to_tensor()\n","    value = tf.strings.to_number([value_as_a_whole], out_type=tf.float32)\n","    # tf.print(key, type(key), tf.shape(key))\n","    # tf.print(value, type(value), tf.shape(value))\n","    title_embd_table.insert(key, value)\n","    return 1\n","\n","tf.data.TFRecordDataset\n","title_embd_ = tf.data.TextLineDataset([DATA_DIR + \"doc_title_embedding.txt\"])\\\n","    .batch(1000)\\\n","    .map(build_title_embd_hash_table)\n","\n","# Must run one pass\n","for ele in title_embd_:\n","    pass"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":526,"status":"ok","timestamp":1697254851060,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"O23AgpVaA1uj","outputId":"34333cf5-9a97-4447-c139-3e2b529d5228"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n","array([[ 0.06875,  0.02232, -0.02387, -0.02996,  0.10184,  0.02768,\n","        -0.04228,  0.01384, -0.02292,  0.0283 , -0.00192, -0.01466,\n","         0.00466, -0.0935 ,  0.02055, -0.03486, -0.00847, -0.00972,\n","        -0.03999,  0.03547,  0.00991,  0.02884,  0.08565, -0.01345,\n","         0.00349, -0.0626 , -0.01813,  0.03217, -0.00993, -0.04048,\n","        -0.01647, -0.06433,  0.02927, -0.00067, -0.00317,  0.04936,\n","        -0.06789,  0.02903, -0.03834,  0.00525, -0.03111, -0.0302 ,\n","        -0.04978, -0.01178, -0.03246,  0.01466,  0.01287, -0.02434,\n","         0.0625 ,  0.02376, -0.11231, -0.06029, -0.06636,  0.03758,\n","        -0.0168 , -0.02797,  0.06975, -0.0041 ,  0.02385,  0.0421 ,\n","        -0.02723, -0.00443, -0.06479,  0.00531,  0.03648,  0.03837,\n","        -0.04302,  0.04137, -0.03322, -0.04695, -0.07088, -0.00611,\n","         0.02463,  0.04293,  0.00055,  0.03174,  0.02429, -0.04159,\n","         0.05676, -0.02921, -0.02157, -0.00119, -0.01214, -0.02329,\n","         0.0595 ,  0.04869,  0.02459,  0.01265,  0.01528,  0.037  ,\n","        -0.07784,  0.00463, -0.04821,  0.02366, -0.0358 ,  0.06225,\n","         0.03198,  0.05025,  0.03704,  0.0721 , -0.02079,  0.00261,\n","         0.02946, -0.01216,  0.04019,  0.06333,  0.01407,  0.00734,\n","        -0.02303, -0.01247,  0.0284 , -0.03929, -0.02886, -0.00311,\n","         0.00633, -0.00811,  0.0113 , -0.05247, -0.02466,  0.04314,\n","        -0.03698,  0.03381,  0.01713,  0.00137,  0.01365,  0.08282,\n","        -0.0352 ,  0.04473,  0.0158 ,  0.03748,  0.00802,  0.03498,\n","         0.02964, -0.01558, -0.03462,  0.01556, -0.02305,  0.01346,\n","         0.03176,  0.02489, -0.00985, -0.05603,  0.00225,  0.02294,\n","        -0.06626,  0.03001, -0.0007 , -0.0666 , -0.03739, -0.04526,\n","        -0.04696,  0.01119, -0.0095 ,  0.01404, -0.01197,  0.03302,\n","        -0.00069, -0.06121, -0.01189, -0.00749, -0.01691, -0.03807,\n","        -0.02012,  0.02877, -0.03066,  0.01522, -0.03313, -0.02573,\n","        -0.00296,  0.00588, -0.00201, -0.0287 ,  0.07172,  0.03485,\n","         0.01055,  0.01576, -0.01797,  0.0025 , -0.01604, -0.02622,\n","         0.02713, -0.01912,  0.01147,  0.00278,  0.03421, -0.03166,\n","        -0.03681, -0.04949, -0.03996,  0.01762,  0.02193,  0.03283,\n","        -0.05515,  0.03401, -0.0319 ,  0.07301, -0.03135,  0.03123,\n","        -0.00703,  0.01259,  0.09876, -0.05983, -0.06288,  0.03135,\n","         0.03201, -0.00066,  0.02957,  0.01838, -0.04829, -0.05527,\n","         0.05224, -0.01153, -0.0505 ,  0.02677,  0.02218, -0.07981,\n","        -0.03858,  0.06949, -0.02304, -0.01112,  0.05969, -0.01649,\n","        -0.04119, -0.04969, -0.05096,  0.01627, -0.00324, -0.00127,\n","        -0.02613, -0.02604,  0.00298,  0.01294, -0.03185,  0.0416 ,\n","         0.03181, -0.05261,  0.00429, -0.00215, -0.02827,  0.03077,\n","         0.00412,  0.04174, -0.09128, -0.01652,  0.01974,  0.00331,\n","         0.00406,  0.01687, -0.01624,  0.03378,  0.00455,  0.04846,\n","        -0.01894, -0.07481,  0.0196 ,  0.04025, -0.04116,  0.04527,\n","         0.02353,  0.04142, -0.02727,  0.10924,  0.00284,  0.08195,\n","        -0.00706,  0.00536,  0.02193, -0.00994,  0.06473, -0.00561,\n","         0.01265, -0.05134,  0.00092, -0.01204,  0.05778, -0.01248,\n","         0.01831,  0.02748, -0.0167 ,  0.0083 , -0.03088,  0.0569 ,\n","        -0.04791,  0.00926,  0.03254, -0.0205 ,  0.06482, -0.03243,\n","         0.02543, -0.02807,  0.01307,  0.04552,  0.0246 , -0.05182,\n","         0.0252 , -0.03056, -0.05261,  0.01737,  0.00615,  0.04706,\n","         0.01917, -0.02502, -0.02086, -0.02718, -0.01732,  0.04243,\n","        -0.03036,  0.04583, -0.00113, -0.01061,  0.0367 ,  0.05323,\n","        -0.04327, -0.05363, -0.03821, -0.00775, -0.00921,  0.0097 ,\n","         0.00505,  0.03853,  0.00722,  0.00746, -0.0092 ,  0.03995,\n","        -0.03817, -0.05064, -0.00889, -0.01829, -0.01949, -0.00729,\n","        -0.01312,  0.01443, -0.108  , -0.02271, -0.02088,  0.04078,\n","         0.01146, -0.09811, -0.02046,  0.0266 ,  0.01747, -0.01631,\n","        -0.00077, -0.00148,  0.01558,  0.0199 , -0.00038,  0.02445,\n","         0.03422,  0.02543, -0.01956,  0.00752,  0.03118,  0.01413,\n","         0.00939,  0.02014,  0.01299,  0.00229, -0.00539, -0.00148,\n","         0.05143,  0.00533,  0.04402, -0.00582, -0.01363, -0.05529,\n","        -0.02836,  0.01237, -0.01761,  0.00875, -0.02768, -0.03992,\n","        -0.03505, -0.0353 , -0.03168,  0.00812, -0.02979,  0.01499,\n","        -0.0092 ,  0.05668, -0.01766,  0.04053, -0.00357, -0.02632,\n","        -0.06131, -0.07174,  0.00949, -0.034  , -0.02574, -0.05745,\n","         0.06661, -0.0089 , -0.02913, -0.02772, -0.01471, -0.08315,\n","         0.00947, -0.03936, -0.01902, -0.01829, -0.02783,  0.0052 ,\n","         0.01179, -0.03682,  0.03324,  0.0358 , -0.01467,  0.0519 ,\n","        -0.0056 ,  0.02018, -0.02943,  0.02871, -0.00979, -0.00894,\n","        -0.04361,  0.02835,  0.00794, -0.07621,  0.0763 ,  0.02757,\n","        -0.03997,  0.00266,  0.00438, -0.04417, -0.00837,  0.01401,\n","         0.00788,  0.00837, -0.03932, -0.01174, -0.00425, -0.06053,\n","         0.0269 , -0.04585, -0.02069, -0.02254,  0.02156,  0.00152,\n","         0.02779, -0.02082,  0.03982,  0.02184,  0.03314,  0.07094,\n","        -0.03371, -0.01307, -0.02792, -0.02336, -0.07332, -0.00225,\n","        -0.04962,  0.01496,  0.01872, -0.0203 , -0.07551, -0.05866,\n","        -0.05808, -0.02375, -0.02543, -0.03507, -0.07533, -0.06809,\n","         0.00957,  0.03313, -0.05815,  0.01633, -0.06447, -0.03745,\n","        -0.00245,  0.00025,  0.01512, -0.01154,  0.00375,  0.02817,\n","        -0.06143, -0.01692, -0.01936,  0.04124, -0.02639, -0.00478,\n","        -0.01277, -0.00562,  0.09457,  0.01524,  0.01295,  0.04742,\n","        -0.0063 ,  0.03076, -0.00425,  0.00776, -0.02062,  0.03035,\n","         0.00949, -0.01913,  0.04427,  0.02676, -0.04693,  0.03914,\n","         0.00894, -0.03319,  0.02404,  0.01066, -0.05168,  0.02092,\n","        -0.01353, -0.02427,  0.06567, -0.02483,  0.05107, -0.01198,\n","         0.06529,  0.00143,  0.03227,  0.06133, -0.01415, -0.0491 ,\n","        -0.03071,  0.03353, -0.02081,  0.01538,  0.03167,  0.00356,\n","         0.04577,  0.02655,  0.0335 , -0.01237,  0.04745,  0.01418,\n","        -0.00698, -0.00528, -0.01796, -0.02752,  0.00977,  0.03518,\n","         0.02341, -0.01948, -0.0265 , -0.02126, -0.00163,  0.05439,\n","         0.00067,  0.01764,  0.05094, -0.02045,  0.03109, -0.03181,\n","         0.07204,  0.04819,  0.01107,  0.03145, -0.00579, -0.00864,\n","         0.00428, -0.04708, -0.01526,  0.02285,  0.01111, -0.02386,\n","         0.05742,  0.00341, -0.0171 , -0.04177, -0.00757,  0.0307 ,\n","        -0.04852,  0.03273,  0.03294, -0.00526, -0.00056,  0.04558,\n","         0.0161 , -0.02177,  0.05169,  0.07672, -0.01274, -0.01586,\n","         0.00916, -0.00447, -0.05782,  0.02969, -0.05314,  0.05946,\n","        -0.01613,  0.01542,  0.00474, -0.04263, -0.04427, -0.04662,\n","         0.02324,  0.04484,  0.00273, -0.09275, -0.02469, -0.00788,\n","        -0.2482 ,  0.01285,  0.02317,  0.02565, -0.03073, -0.00476,\n","         0.01453,  0.00887,  0.0737 ,  0.01491,  0.00318,  0.05477,\n","        -0.01387,  0.00894, -0.02924,  0.04489,  0.00626,  0.01165,\n","        -0.01761, -0.01774, -0.04536, -0.00081, -0.02616, -0.01551,\n","         0.01281,  0.01786, -0.01344,  0.01101, -0.0445 , -0.05215,\n","         0.00763, -0.01308,  0.05646, -0.01123,  0.00286, -0.01887,\n","        -0.00593,  0.00182,  0.02901,  0.04497, -0.03059, -0.04571,\n","        -0.02313,  0.01186,  0.00733, -0.01053, -0.06638, -0.01787,\n","        -0.05065, -0.04304,  0.00292, -0.00334,  0.01401, -0.01747,\n","         0.011  ,  0.03388, -0.00093, -0.00705,  0.04682,  0.0286 ,\n","         0.0158 , -0.03474, -0.01418, -0.00072, -0.00356, -0.04399,\n","        -0.01909,  0.03409,  0.04286,  0.0395 ,  0.0367 ,  0.0492 ,\n","         0.04092, -0.00792,  0.00137,  0.00702,  0.02534,  0.00601,\n","        -0.01867, -0.00061, -0.04511,  0.02395, -0.02813, -0.01918,\n","         0.01468,  0.00995,  0.01331,  0.03091,  0.0286 ,  0.02291,\n","        -0.0618 ,  0.02447,  0.07156,  0.02007, -0.00311,  0.00577,\n","        -0.01096,  0.00676,  0.01133, -0.01117, -0.01318,  0.01807,\n","        -0.04474,  0.01775,  0.00727, -0.01448,  0.0008 ,  0.05098,\n","        -0.00904,  0.00051,  0.05222,  0.01112,  0.01641, -0.0005 ,\n","         0.00354,  0.01453, -0.01936, -0.01909, -0.06949,  0.02371,\n","         0.05628, -0.00871,  0.07713,  0.02403, -0.00111,  0.00961,\n","         0.02754, -0.05244, -0.02009,  0.01506, -0.02805, -0.00376,\n","         0.05102,  0.02991, -0.04112,  0.07348,  0.00687,  0.00214,\n","         0.01095,  0.00961,  0.00688, -0.00527,  0.02605, -0.04951,\n","         0.01443, -0.00718,  0.06864, -0.03083, -0.04465, -0.03527,\n","        -0.02908, -0.00633, -0.05324, -0.06117, -0.01979, -0.05134,\n","         0.01752, -0.00081, -0.00221, -0.02697,  0.06379, -0.01695,\n","         0.02601,  0.04368, -0.00186,  0.04513,  0.01425, -0.05651,\n","         0.05698,  0.06255,  0.03608,  0.01175, -0.02043,  0.03074]],\n","      dtype=float32)>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["title_embd_table.lookup(tf.constant([349635709], tf.int64))"]},{"cell_type":"markdown","metadata":{"id":"CacTJzg-aIGr"},"source":["## other feature (normal)"]},{"cell_type":"markdown","metadata":{"id":"Sf4dFDGzaIGs"},"source":["### build user MutableHashTable, to build feature later"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4542,"status":"ok","timestamp":1697254877267,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"78-ZkImyaIGs"},"outputs":[],"source":["# 用户id、设备名称、操作系统、所在省、所在市、年龄、性别；\n","\n","user_info_table = tf.lookup.experimental.MutableHashTable(\n","        key_dtype=tf.int64,\n","        value_dtype=tf.string,\n","        default_value=[\"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"],\n","    )\n","\n","\n","def build_hash_table(ele):\n","    # tf.print(ele[:, 0], type(ele), ele.shape)\n","    key = tf.strings.to_number([ele[:, 0]], out_type=tf.int64)\n","    # tf.print(key, type(key), key.shape)\n","    # tf.print(key)\n","    user_info_table.insert(key, tf.expand_dims(ele, axis=0))\n","    return 1\n","\n","\n","user_info_ = tf.data.Dataset.from_tensor_slices(user_info)\\\n","    .batch(1000)\\\n","    .map(build_hash_table)\n","\n","# Must run one pass\n","for ele in user_info_:\n","    pass"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697254880736,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"0QTZFOQQaIGt","outputId":"0dd634c3-a77c-4794-d4c6-73227268a7a3"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 7), dtype=string, numpy=\n","array([[b'1001384888', b'M2007J22C', b'Android',\n","        b'\\xe6\\xb2\\xb3\\xe5\\x8c\\x97',\n","        b'\\xe7\\x9f\\xb3\\xe5\\xae\\xb6\\xe5\\xba\\x84', b'A_40+', b'male']],\n","      dtype=object)>"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["user_info_table.lookup(tf.constant([1001384888], dtype=tf.int64))"]},{"cell_type":"markdown","metadata":{"id":"UM527jCyUCcB"},"source":["### build doc MutableHashTable"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":5093,"status":"ok","timestamp":1697254891281,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"-yGAcM7WUAFy"},"outputs":[],"source":["# 文章id、标题、发文时间、图片数量、一级分类、二级分类、关键词；\n","doc_info_table = tf.lookup.experimental.MutableHashTable(\n","        key_dtype=tf.int64,\n","        value_dtype=tf.string,\n","        default_value=[\"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"],\n","    )\n","\n","\n","def build_doc_hash_table(ele):\n","    # tf.print(ele[:, 0], type(ele), ele.shape)\n","    key = tf.strings.to_number([ele[:, 0]], out_type=tf.int64)\n","    # tf.print(key, type(key), key.shape)\n","    # tf.print(key)\n","    doc_info_table.insert(key, tf.expand_dims(ele, axis=0))\n","    return 1\n","\n","\n","doc_info_ = tf.data.Dataset.from_tensor_slices(doc_info)\\\n","    .batch(1000)\\\n","    .map(build_doc_hash_table)\n","\n","# Must run one pass\n","for ele in doc_info_:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"EilqNCyraIGt"},"source":["### make feat by tf method"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":876,"status":"ok","timestamp":1697255168139,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"GFNo121RaIGt"},"outputs":[],"source":["# 用户id、文章id、展现时间、网路环境、刷新次数、展现位置、是否点击、消费时长（秒）；\n","user_feat_location = {name: idx for idx, name in enumerate(user_info_cols)}\n","doc_feat_location = {name: idx for idx, name in enumerate(doc_info_cols)}\n","show_feat_location = {name: idx for idx, name in enumerate(show_info_cols)}\n","\n","\n","def tf_get_feat_from_table(ele: tf.Tensor):\n","    ele: tf.Tensor = tf.strings.split(ele, \"\\t\").to_tensor()\n","    uids = tf.strings.to_number([ele[:, 0]], out_type=tf.int64)\n","    docids = tf.strings.to_number([ele[:, 1]], out_type=tf.int64)\n","    label = tf.strings.to_number([ele[:, 6]], out_type=tf.int64)\n","    label = tf.reshape(label, shape=[-1, 1])  # [1, batch] to [batch, 1]\n","    # tf.print(label, type(label), tf.shape(label))\n","    user_feat_values = user_info_table.lookup(uids)\n","    user_feat_values = tf.squeeze(user_feat_values, axis=0)\n","\n","    doc_feat_values = doc_info_table.lookup(docids)\n","    doc_feat_values = tf.squeeze(doc_feat_values, axis=0)\n","    # tf.print(doc_feat_values, type(doc_feat_values), tf.shape(doc_feat_values))\n","\n","    title_embd_values = title_embd_table.lookup(docids)\n","    title_embd_values = tf.squeeze(title_embd_values, axis=0)\n","\n","    # tf.print(title_embd_values, type(title_embd_values), tf.shape(title_embd_values))\n","\n","    feat_dict = {}\n","    for feat in feat_names:\n","        if feat == \"title\":\n","            tmp = title_embd_values\n","        elif feat in user_feat_location:\n","            tmp = user_feat_values[:, user_feat_location[feat]]\n","        elif feat in doc_feat_location:\n","            tmp = doc_feat_values[:, doc_feat_location[feat]]\n","        else:\n","            tmp = ele[:, show_feat_location[feat]]\n","\n","        if feat == \"title\":\n","            tmp = tf.ensure_shape(tmp, [None, 768])\n","        else:\n","            tmp = converter_layers[feat](tmp)\n","            tmp = tf.ensure_shape(tmp, [None,])\n","\n","        feat_dict[feat] = tmp\n","    return (feat_dict, label)\n","\n","\n","\n","train_show_log = tf.data.TextLineDataset([DATA_DIR + \"sorted_train_data.txt\"])\\\n","    .batch(1024, drop_remainder=True)\\\n","    .map(tf_get_feat_from_table)\n","    # .unbatch()"]},{"cell_type":"markdown","metadata":{"id":"fSHcrw9eaIGu"},"source":["### concat show log and req feat"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":583,"status":"ok","timestamp":1697255172940,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"86lieUdBaIGu"},"outputs":[],"source":["def merge_sparse_with_seq_into_one_dict(a, seq):\n","    sparse, label = a\n","    for _, value in sparse.items():\n","        value.set_shape([1024])\n","    sparse[\"docid_seq\"] = seq\n","    return (sparse, label)\n","\n","if \"docid\" in feat_names:\n","    dataset = tf.data.Dataset.zip((train_show_log, seq_dataset)).map(merge_sparse_with_seq_into_one_dict).prefetch(tf.data.AUTOTUNE)\n","else:\n","    dataset = train_show_log.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697255174396,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"OKBtGaYmaIGu"},"outputs":[],"source":["# train_dataset, test_dataset = tf.keras.utils.split_dataset(dataset.take(1_000_000), left_size=0.9)\n","# dataset has approximately 185319 batches.\n","\n","if IS_COLAB_ENV:\n","    train_dataset = dataset.take(100_000)\n","    test_dataset = dataset.skip(100_000).take(30_000)\n","else:\n","    train_dataset = dataset.take(100)\n","    test_dataset = dataset.skip(100).take(30)"]},{"cell_type":"markdown","metadata":{"id":"2wjkNBjjaIGu"},"source":["### make negative sample"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1697254905218,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"luyim2P7aIGv"},"outputs":[],"source":["# 用户id、文章id、展现时间、网路环境、刷新次数、展现位置、是否点击、消费时长（秒）；\n","\n","# doc_click_freq = tf.lookup.experimental.MutableHashTable(\n","#     key_dtype=tf.int64,\n","#     value_dtype=tf.int64,\n","#     default_value=0,\n","# )\n","\n","\n","# def split_ele(ele):\n","#     return tf.strings.split(ele, \"\\t\")\n","\n","\n","# def is_click(ele):\n","#     res = (ele[6] == tf.constant([\"1\"]))\n","#     # tf.print(res[0], type(res[0]))\n","#     return res[0]\n","\n","\n","# click_log_dataset = tf.data.TextLineDataset(DATA_DIR + \"/sorted_train_data.txt\")\\\n","#     .map(split_ele)\n","#     .filter(is_click)\n","\n","# for e in click_log_dataset.take(10):\n","#     print(e)\n","#     pass"]},{"cell_type":"markdown","metadata":{"id":"vRNMbxO-aIGw"},"source":["# TRAIN MODEL"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1697254906795,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"tOVTvcRBA1um"},"outputs":[],"source":["%load_ext tensorboard"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":672,"status":"ok","timestamp":1697255191727,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"xcnq2v0yaIGx","outputId":"cb120c9d-6890-4a06-99da-97e460456bf2"},"outputs":[{"name":"stdout","output_type":"stream","text":["userid embedding space size is 1538385\n","device embedding space size is 3097\n","operating_system embedding space size is 4\n","province embedding space size is 329\n","city embedding space size is 769\n","age embedding space size is 6\n","gender embedding space size is 4\n","network embedding space size is 5\n","rt embedding space size is 215\n","rit embedding space size is 1185\n","cate1 embedding space size is 40\n","cate2 embedding space size is 202\n"]}],"source":["import importlib\n","import model\n","import datetime\n","importlib.reload(model)\n","\n","sparse_configs = []\n","doc_embedding = None\n","dense_configs = []\n","\n","# feat_names = [\n","#     \"userid\",\n","#     \"device\",\n","#     \"operating_system\",\n","#     \"province\",\n","#     \"city\",\n","#     \"age\",\n","#     \"gender\",\n","#     # \"docid\",\n","#     \"network\",\n","#     \"rt\",\n","#     \"rit\",\n","#     \"cate1\",\n","#     \"cate2\",\n","#     \"title\",\n","# ]\n","\n","for feat in feat_names:\n","    layer = converter_layers[feat]\n","    if feat == \"cate2\":\n","        doc_embedding = model.EmbeddingConfig(feat, 64, layer.vocabulary_size())\n","    elif feat == \"title\":\n","        dense_configs.append(\n","            model.DenseConfig(\"title\", 768)\n","        )\n","        continue\n","    elif feat in [\"userid\", \"device\", \"rit\"]:\n","        sparse_configs.append(\n","            model.EmbeddingConfig(feat, 16, layer.vocabulary_size())\n","        )\n","    else:\n","        sparse_configs.append(\n","            model.EmbeddingConfig(feat, 64, layer.vocabulary_size())\n","        )\n","    print(\"{} embedding space size is {}\".format(feat, layer.vocabulary_size()))\n","\n","with tf.device(device_name):\n","    optimizer = keras.optimizers.Adam()\n","    youtubednn = model.YouTubeDNN(\n","        sparse_configs, doc_embedding, use_seq_feat=False, dense_feat=dense_configs, dnn_dims=[1024, 512],\n","        # text_feat=[\"title\"], text_transformer=converter_layers[\"title\"]\n","    )\n","    youtubednn.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.BinaryCrossentropy(from_logits=False),\n","        metrics=keras.metrics.AUC(),\n","    )"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":870,"status":"ok","timestamp":1697255194685,"user":{"displayName":"Shen Han","userId":"02463852277525791803"},"user_tz":-480},"id":"1Mi927dS6-8Z"},"outputs":[],"source":["checkpoint_dir = \"./ckpt_1014_bert/\"\n","checkpoint_filepath = checkpoint_dir + \"{epoch:02d}-{val_auc:.3f}.hdf5\"\n","\n","# epoch = tf.Variable(0)\n","EPOCHS = 2\n","\n","# other_ckpt = tf.train.Checkpoint(\n","#     optimizer=optimizer,\n","#     epoch = epoch,\n","# )\n","# other_chkpt_manager = tf.train.CheckpointManager(\n","#     other_ckpt,\n","#     checkpoint_dir,\n","#     max_to_keep=3,\n","# )\n","\n","class CheckPointCallback(keras.callbacks.ModelCheckpoint):\n","    def on_epoch_end(self, epoch, logs=None):\n","        keys = list(logs.keys())\n","        for key in keys:\n","            if key.startswith(\"val_auc\"):\n","                logs[\"val_auc\"] = logs[key]\n","                break\n","        keras.callbacks.ModelCheckpoint.on_epoch_end(self, epoch, logs)\n","        # ckpt_save_path = other_chkpt_manager.save()\n","        # print(f'Saving checkpoint for epoch {epoch} at {ckpt_save_path}')\n","        # other_ckpt.epoch.assign_add(1)\n","\n","model_checkpoint_callback = CheckPointCallback(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor=\"val_auc\",\n","    mode=\"max\",\n","    save_best_only=True,\n","    verbose=1,\n",")\n","\n","# backup_and_restore = keras.callbacks.BackupAndRestore(\n","#     backup_dir=checkpoint_dir[:-1] + \"_backup\",\n","#     save_freq=100000)\n","\n","log_dir = checkpoint_dir + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","def get_latext_ckpt():\n","    init_epoch = 0\n","    max_auc = 0\n","    ckpt_name = None\n","    try:\n","        file_names = os.listdir(checkpoint_dir)\n","    except:\n","        return init_epoch, max_auc, ckpt_name\n","    if len(file_names) > 0:\n","        for file_name in file_names:\n","            if file_name in [\"logs\"]:\n","                continue\n","            file_name_without_ext = file_name[:-5]\n","            epoch_str, auc_str = file_name_without_ext.split(\"-\")\n","            epoch = int(epoch_str)\n","            auc = float(auc_str)\n","            if max_auc <= auc:\n","                max_auc = auc\n","                init_epoch = epoch\n","                ckpt_name = checkpoint_dir + file_name\n","    return init_epoch, max_auc, ckpt_name\n","\n","init_epoch, _, ckpt_name = get_latext_ckpt()\n","\n","if ckpt_name is not None:\n","    youtubednn.evaluate(train_dataset.take(1))\n","    youtubednn.load_weights(ckpt_name)\n","    print(\"Load file \"+ckpt_name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-epy4DCA6-8Z","outputId":"ba0d0b9b-1fde-431f-9cf0-ede09dabd003"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","100000/100000 [==============================] - ETA: 0s - loss: 0.3576 - auc_1: 0.7562"]}],"source":["# if other_chkpt_manager.latest_checkpoint:\n","#     youtubednn.load_weights(checkpoint_dir)\n","#     other_ckpt.restore(other_chkpt_manager.latest_checkpoint)\n","#     print(f'Latest checkpoint restored!!. Last epoch is {int(epoch)}')\n","# else:\n","#     print(\"Didn't find checkpoint. Train from scratch.\")\n","\n","\n","youtubednn.fit(\n","    x = train_dataset,\n","    validation_data=test_dataset,\n","    callbacks=[\n","        model_checkpoint_callback,\n","        # backup_and_restore,\n","        tensorboard_callback,\n","    ],\n","    epochs=EPOCHS,\n","    initial_epoch=init_epoch,\n","    steps_per_epoch=100_000,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2eQLAFZ81Eq"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
