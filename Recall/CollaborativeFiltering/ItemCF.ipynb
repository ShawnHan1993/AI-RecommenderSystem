{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description：\n",
    "这个笔记本尝试实现一下项亮推荐系统实践里面的ItemCF算法， 采用的数据集是GroupLens提供的MovieLens的其中一个小数据集ml-latest-small。 该数据及包含700个用户对带有6100个标签的10000部电影的100000条评分。 该数据集是一个评分数据集， 用户可以给电影评5个不同等级的分数(1-5)， 而由于我们主要是研究隐反馈数据中的topN推荐问题， 所以忽略了数据集中的评分记录。  **TopN推荐的任务是预测用户会不会对某部电影评分， 而不是预测用户在准备对某部电影评分的前提下给电影评多少分**， 下面我们开始， 从逻辑上看， 其实这个任务主要分为下面的步骤：\n",
    "1. 导入数据， 读取文件得到\"用户-电影\"的评分数据， 并且分为训练集和测试集\n",
    "2. 计算电影之间的相似度\n",
    "3. 针对目标用户u， 找到其最相似的k个用户， 产生N个推荐\n",
    "4. 产生推荐之后， 通过准确率、召回率和覆盖率等进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T02:51:36.893798Z",
     "start_time": "2020-08-21T02:51:36.384451Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入数据\n",
    "读取文件得到\"用户-电影\"的评分数据， 并且分为训练集和测试集， 这里的思想是首先给出数据存在的路径， 然后通过pandas读取数据， 然后遍历该数据集， 把相应的数据存放到字典中， 这里之所以会用字典， 是因为用户对电影的评分会存在大量的稀疏。 所以我们依然需要建立一个\"{用户：{电影: 评分}}\"的这样一个字典， 后面基于这个字典去计算相似度。 如果感觉下面的代码理解有困难， 可以先参考我给出的博客链接补一下基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T02:51:38.853082Z",
     "start_time": "2020-08-21T02:51:38.799808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './ml-latest-small/'\n",
    "data = pd.read_csv(data_path+'ratings.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T02:51:40.089643Z",
     "start_time": "2020-08-21T02:51:40.008683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>193565</th>\n",
       "      <th>193567</th>\n",
       "      <th>193571</th>\n",
       "      <th>193573</th>\n",
       "      <th>193579</th>\n",
       "      <th>193581</th>\n",
       "      <th>193583</th>\n",
       "      <th>193585</th>\n",
       "      <th>193587</th>\n",
       "      <th>193609</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1       2       3       4       5       6       7       8       \\\n",
       "userId                                                                    \n",
       "1           4.0     NaN     4.0     NaN     NaN     4.0     NaN     NaN   \n",
       "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "606         2.5     NaN     NaN     NaN     NaN     NaN     2.5     NaN   \n",
       "607         4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         2.5     2.0     2.0     NaN     NaN     NaN     NaN     NaN   \n",
       "609         3.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         5.0     NaN     NaN     NaN     NaN     5.0     NaN     NaN   \n",
       "\n",
       "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
       "userId                   ...                                                   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "5           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "606         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "607         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "608         NaN     4.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "609         NaN     4.0  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "610         NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  193583  193585  193587  193609  \n",
       "userId                                   \n",
       "1           NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN  \n",
       "4           NaN     NaN     NaN     NaN  \n",
       "5           NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...  \n",
       "606         NaN     NaN     NaN     NaN  \n",
       "607         NaN     NaN     NaN     NaN  \n",
       "608         NaN     NaN     NaN     NaN  \n",
       "609         NaN     NaN     NaN     NaN  \n",
       "610         NaN     NaN     NaN     NaN  \n",
       "\n",
       "[610 rows x 9724 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pivot(index='userId', columns='movieId', values='rating')   # 这样会发现有大量的稀疏， 所以才会用字典进行存放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T02:51:43.492328Z",
     "start_time": "2020-08-21T02:51:43.311441Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split trainingSet and testSet success!\n",
      "TrainSet = 75603\n",
      "TestSet = 25233\n"
     ]
    }
   ],
   "source": [
    "# 声明两个字典， 分别是训练集和测试集\n",
    "trainSet, testSet = {}, {}\n",
    "trainSet_len, testSet_len = 0, 0\n",
    "pivot = 0.75    # 训练集的比例\n",
    "\n",
    "# 遍历data的每一行， 把userId, movidId, rating按照{user: {movidId: rating}}的方式存储， 当然定义一个随机种子进行数据集划分\n",
    "for ele in data.itertuples():   # 遍历行这里推荐用itertuples， 比iterrows会高效很多\n",
    "    user, movie, rating = getattr(ele, 'userId'), getattr(ele, 'movieId'), getattr(ele, 'rating')\n",
    "    if random.random() < pivot:\n",
    "        trainSet.setdefault(user, {})\n",
    "        trainSet[user][movie] = rating\n",
    "        trainSet_len += 1\n",
    "    else:\n",
    "        testSet.setdefault(user, {})\n",
    "        testSet[user][movie] = rating \n",
    "        testSet_len += 1\n",
    "\n",
    "print('Split trainingSet and testSet success!')\n",
    "print('TrainSet = %s' % trainSet_len)\n",
    "print('TestSet = %s' % testSet_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算电影之间的相似度\n",
    "和UserItemCF相似， 这里同样需要建立一个倒排表， 只不过这里的倒排变成了{用户：物品}的倒排表， 如下：\n",
    "\n",
    "![](./images/3.png)\n",
    "\n",
    "而比较巧的是， 我们这里的存储正好是“用户-物品\"评分表， 所以现在正好是倒排的形式， 所以不用刻意建立建立倒排表， 直接遍历trainSet即可.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_key_by_two_movies(m1, m2):\n",
    "    if m1 < m2:\n",
    "        return (m1, m2)\n",
    "    else:\n",
    "        return (m2, m1)\n",
    "\n",
    "\n",
    "dividen_map = {}\n",
    "divisor_map = {}\n",
    "\n",
    "for user, movies_dict_watched_by_this_user in trainSet.items():\n",
    "    movies_list_watched_by_this_user = list(movies_dict_watched_by_this_user.keys())\n",
    "    for i in range(len(movies_list_watched_by_this_user) - 1):\n",
    "        for j in range(i + 1, len(movies_list_watched_by_this_user)):\n",
    "            one_movie = movies_list_watched_by_this_user[i]\n",
    "            the_other = movies_list_watched_by_this_user[j]\n",
    "            key = _get_key_by_two_movies(one_movie, the_other)\n",
    "            dividen_map.setdefault(key, 0)\n",
    "            dividen_map[key] += movies_dict_watched_by_this_user[one_movie] * movies_dict_watched_by_this_user[the_other]\n",
    "\n",
    "            divisor_map.setdefault(one_movie, 0)\n",
    "            divisor_map[one_movie] += movies_dict_watched_by_this_user[one_movie] ** 2\n",
    "\n",
    "            divisor_map.setdefault(the_other, 0)\n",
    "            divisor_map[the_other] += movies_dict_watched_by_this_user[the_other] ** 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 针对目标用户u， 找到其评分的所有movies中最相似的k个moives， 产生N个推荐\n",
    "得到物品相似度后， ItemCF算法通过下面公式计算用户u对物品j的兴趣：\n",
    "$$p_{u j}=\\sum_{i \\in N(u) \\cap S(j, K)} w_{j i} r_{u i}$$\n",
    "其中， $S(j,k)$是和物品j最相似的K个物品的集合， $N(u)$是用户喜欢的物品的集合， $w_{ji}$是物品j和物品i的相似度， $r_{ui}$代表用户u对物品i的兴趣， 因为使用单一行为的隐反馈数据， 所以这里$r_{ui}=1$, 该公式的含义是， 和用户历史上感兴趣的物品越相似的物品， 越有可能在用户的推荐列表中获得较高的排名<br><br>\n",
    "\n",
    "所以下面的代码逻辑是这样：\n",
    "* 首先， 给定我一个用户ID， 我先拿到这个用户ID目前看过的所有电影， 以防后面推荐重了。  \n",
    "* 然后从相似性矩阵中，找到与当前用户看的物品的最相近的K个物品\n",
    "* 遍历他们看过的电影， 如果当前用户没有看过， 该电影的权重等级累加\n",
    "* 最后给所有的电影进行排序， 推荐前n部给当前用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "def predict(u, i, k=None):\n",
    "    if i in trainSet[u]:\n",
    "        return trainSet[u][i]\n",
    "    score_dividen = 0\n",
    "    score_divisor = 0\n",
    "    if i not in divisor_map:\n",
    "        return 0\n",
    "    i_divisor = math.sqrt(divisor_map[i])\n",
    "    if k is None or len(trainSet[u]) <= k:\n",
    "        to_be_considered_movies = []\n",
    "        for movie, rating in trainSet[u].items():\n",
    "            key = _get_key_by_two_movies(i, movie)\n",
    "            dividen_map.setdefault(key, 0)\n",
    "            dividen = dividen_map[key]\n",
    "            if movie in divisor_map:\n",
    "                divisor = i_divisor * math.sqrt(divisor_map[movie])\n",
    "                sim = dividen / divisor\n",
    "            else:\n",
    "                sim = 0\n",
    "            to_be_considered_movies.append((sim, rating))\n",
    "    else:\n",
    "        heap = []\n",
    "        for movie, rating in trainSet[u].items():\n",
    "            key = _get_key_by_two_movies(i, movie)\n",
    "            dividen_map.setdefault(key, 0)\n",
    "            dividen = dividen_map[key]\n",
    "            if movie in divisor_map:\n",
    "                divisor = i_divisor * math.sqrt(divisor_map[movie])\n",
    "                sim = dividen / divisor\n",
    "            else:\n",
    "                sim = 0\n",
    "            heap.append((sim, rating))\n",
    "        to_be_considered_movies = nlargest(k, heap)\n",
    "    for sim, rating in to_be_considered_movies:\n",
    "        score_dividen += sim * rating\n",
    "        score_divisor += sim\n",
    "    if score_divisor == 0:\n",
    "        return 0\n",
    "    return score_dividen / score_divisor\n",
    "\n",
    "def get_rec_list(u, n):\n",
    "    heap = []\n",
    "    for movie in divisor_map:\n",
    "        if movie in trainSet[u]:\n",
    "            continue\n",
    "        heap.append((predict(u, movie, 10), movie))\n",
    "    return nlargest(n, heap)\n",
    "\n",
    "# get_rec_list(1, 100)\n",
    "# predict(1, 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "ground_truth = []\n",
    "score = []\n",
    "baseline = []\n",
    "for user, movies_watched_by_this_user in testSet.items():\n",
    "    ground_truth_one_sample = []\n",
    "    score_one_sample = []\n",
    "    baseline_one_sample = []\n",
    "    for movie, rating in list(movies_watched_by_this_user.items())[:20]:\n",
    "        ground_truth_one_sample.append(rating)\n",
    "        score_ = predict(user, movie, 20)\n",
    "        score_one_sample.append(score_)\n",
    "        baseline_one_sample.append(random.random() * 5)\n",
    "    if len(ground_truth_one_sample) < 20:\n",
    "        continue\n",
    "    ground_truth.append(ground_truth_one_sample)\n",
    "    score.append(score_one_sample)\n",
    "    baseline.append(baseline_one_sample)\n",
    "\n",
    "\n",
    "print(\"cf: \", ndcg_score(np.asarray(ground_truth), np.asarray(score)))\n",
    "print(\"random: \", ndcg_score(np.asarray(ground_truth), np.asarray(baseline)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 1, 6]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/hvhmkm4d2t9dwbktnwl14s2w0000gn/T/ipykernel_22041/813119624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m ndcg_score(\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/.venv/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mndcg_score\u001b[0;34m(y_true, y_score, k, sample_weight, ignore_ties)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1617\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1618\u001b[0m     \u001b[0m_check_dcg_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ndcg_sample_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_ties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_ties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 1, 6]"
     ]
    }
   ],
   "source": [
    "gt = [1, 2, 3, 4, 5, 6]\n",
    "a = np.asarray([gt])\n",
    "counter = 0\n",
    "# a_li = []\n",
    "b_li = []\n",
    "sm_w = []\n",
    "while counter < 6:\n",
    "    sm_w.append((2 ** gt[counter] - 1) / gt[counter])\n",
    "    b_li.append(random.random()*6)\n",
    "    counter += 1\n",
    "# a = np.asarray([a_li])\n",
    "b = np.asarray([b_li])\n",
    "c = np.asarray(sm_w)\n",
    "\n",
    "ndcg_score(\n",
    "    a, b,\n",
    "    sample_weight=c\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 产生推荐之后， 通过准确率、召回率和覆盖率等进行评估。\n",
    "这里介绍评测指标：<br><br>\n",
    "1. 召回率<br>\n",
    "对用户u推荐N个物品记为$R(u)$, 令用户u在测试集上喜欢的物品集合为$T(u)$， 那么召回率定义为：\n",
    "$$\\operatorname{Recall}=\\frac{\\sum_{u}|R(u) \\cap T(u)|}{\\sum_{u}|T(u)|}$$\n",
    "这个意思就是说， 在用户真实购买或者看过的影片里面， 我模型真正预测出了多少， 这个考察的是模型推荐的一个全面性。 <br>\n",
    "\n",
    "2. 准确率<br>\n",
    "准确率定义为：\n",
    "$$\\operatorname{Precision}=\\frac{\\sum_{u} \\mid R(u) \\cap T(u)}{\\sum_{u}|R(u)|}$$\n",
    "这个意思再说， 在我推荐的所有物品中， 用户真正看的有多少， 这个考察的是我模型推荐的一个准确性。 <br><br>\n",
    "为了提高准确率， 模型需要把非常有把握的才对用户进行推荐， 所以这时候就减少了推荐的数量， 而这往往就损失了全面性， 真正预测出来的会非常少，所以实际应用中应该综合考虑两者的平衡。\n",
    "\n",
    "3. 覆盖率\n",
    "覆盖率反映了推荐算法发掘长尾的能力， 覆盖率越高， 说明推荐算法越能将长尾中的物品推荐给用户。\n",
    "$$\\text { Coverage }=\\frac{\\left|\\bigcup_{u \\in U} R(u)\\right|}{|I|}$$\n",
    "该覆盖率表示最终的推荐列表中包含多大比例的物品。如果所有物品都被给推荐给至少一个用户， 那么覆盖率是100%。\n",
    "\n",
    "4. 新颖度\n",
    "用推荐列表中物品的平均流行度度量推荐结果的新颖度。 如果推荐出的物品都很热门， 说明推荐的新颖度较低。  由于物品的流行度分布呈长尾分布， 所以为了流行度的平均值更加稳定， 在计算平均流行度时对每个物品的流行度取对数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T03:10:11.674618Z",
     "start_time": "2020-08-21T03:10:11.668633Z"
    }
   },
   "outputs": [],
   "source": [
    "# 这里先把产生推荐的那个封装成函数才能测试所有的测试样本\n",
    "def recommend(aim_user, k=20, n=10):\n",
    "    rank ={}\n",
    "    watched_movies = trainSet[aim_user]      # 找出目标用户看到电影\n",
    "\n",
    "    for movie, rating in watched_movies.items():\n",
    "        #遍历与物品item最相似的前k个产品，获得这些物品及相似分数\n",
    "        for related_movie, w in sorted(movie_sim_matrix[movie].items(), key=itemgetter(1), reverse=True)[:k]:\n",
    "            # 若该物品用户看过， 跳过\n",
    "            if related_movie in watched_movies:\n",
    "                continue\n",
    "\n",
    "            # 计算用户user对related_movie的偏好值， 初始化该值为0\n",
    "            rank.setdefault(related_movie, 0)\n",
    "            #通过与其相似物品对物品related_movie的偏好值相乘并相加。\n",
    "            #排名的依据—— > 推荐电影与该已看电影的相似度(累计) * 用户对已看电影的评分\n",
    "            rank[related_movie] += w * float(rating)\n",
    "\n",
    "    # 产生最后的推荐列表\n",
    "    return sorted(rank.items(), key=itemgetter(1), reverse=True)[:n]  # itemgetter(1) 是简洁写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-21T03:12:00.547343Z",
     "start_time": "2020-08-21T03:10:42.508463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisioin = 0.2738\n",
      "recall = 0.0666\n",
      "coverage = 0.0680\n",
      "popularity = 4.5310\n"
     ]
    }
   ],
   "source": [
    "# 准确率、召回率和覆盖率\n",
    "hit = 0\n",
    "rec_count = 0     # 统计推荐的影片数量， 计算查准率\n",
    "test_count = 0    # 统计测试集的影片数量， 计算查全率\n",
    "all_rec_movies = set()    # 统计被推荐出来的影片个数， 无重复了， 为了计算覆盖率\n",
    "item_populatity = dict()   # 计算新颖度\n",
    "\n",
    "# 先计算每部影片的流行程度\n",
    "for user, items in trainSet.items():\n",
    "    for item in items.keys():\n",
    "        if item not in item_populatity:\n",
    "            item_populatity[item] = 0\n",
    "        item_populatity[item] += 1    # 这里统计训练集中每部影片用户观看的总次数， 代表每部影片的流行程度\n",
    "\n",
    "\n",
    "# 计算评测指标\n",
    "ret = 0\n",
    "ret_cou = 0\n",
    "for user, items in trainSet.items():    # 这里得保证测试集里面的用户在训练集里面才能推荐\n",
    "    \n",
    "    test_movies = testSet.get(user, {})\n",
    "    rec_movies = recommend(user)\n",
    "    for movie, w in rec_movies:\n",
    "        if movie in test_movies:\n",
    "            hit += 1\n",
    "        all_rec_movies.add(movie)\n",
    "        ret += math.log(1+item_populatity[movie])\n",
    "        ret_cou += 1\n",
    "    rec_count += n\n",
    "    test_count += len(test_movies)\n",
    "    \n",
    "    \n",
    "precision = hit / (1.0 * rec_count)\n",
    "recall = hit / (1.0 * test_count)\n",
    "coverage = len(all_rec_movies) / movie_count\n",
    "ret /= ret_cou*1.0\n",
    "    \n",
    "print('precisioin = %.4f\\nrecall = %.4f\\ncoverage = %.4f\\npopularity = %.4f' % (precision, recall, coverage, ret))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
